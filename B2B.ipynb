{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# # Load the Phi-2 model and tokenizer\n",
    "# model_name = \"microsoft/phi-2\"  \n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain langchain-community\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.llms import Ollama\n",
    "\n",
    "# # Load LLaMA 2 model using Ollama\n",
    "# llm = Ollama(model=\"llama2\", temperature=0.7)\n",
    "\n",
    "# # Example usage\n",
    "# prompt = \"Explain quantum computing in simple terms.\"\n",
    "# response = llm(prompt)\n",
    "# print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !pip install spacy\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# import re\n",
    "\n",
    "# # Load spaCy model\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# # Function to extract information from CV text\n",
    "# def extract_cv_info(cv_text):\n",
    "#     # Initialize a dictionary to store the extracted information\n",
    "#     cv_data = {\n",
    "#         \"name\": None,\n",
    "#         \"contact\": {\"email\": None, \"phone\": None},\n",
    "#         \"education\": [],\n",
    "#         \"experience\": [],\n",
    "#         \"skills\": []\n",
    "#     }\n",
    "\n",
    "#     # Extract name using spaCy's NER\n",
    "#     doc = nlp(cv_text)\n",
    "#     for ent in doc.ents:\n",
    "#         if ent.label_ == \"PERSON\":  # Assuming the first PERSON entity is the name\n",
    "#             cv_data[\"name\"] = ent.text\n",
    "#             break\n",
    "\n",
    "#     # Extract email and phone using regex\n",
    "#     email_pattern = r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\"\n",
    "#     phone_pattern = r\"\\+?\\d[\\d -]{8,12}\\d\"\n",
    "#     cv_data[\"contact\"][\"email\"] = re.findall(email_pattern, cv_text)[0]\n",
    "#     cv_data[\"contact\"][\"phone\"] = re.findall(phone_pattern, cv_text)[0]\n",
    "\n",
    "#     # Extract education\n",
    "#     education_section = re.search(r\"Education:(.*?)(Experience:|Skills:|$)\", cv_text, re.DOTALL)\n",
    "#     if education_section:\n",
    "#         education_lines = education_section.group(1).strip().split(\"\\n\")\n",
    "#         cv_data[\"education\"] = [line.strip() for line in education_lines if line.strip()]\n",
    "\n",
    "#     # Extract experience\n",
    "#     experience_section = re.search(r\"Experience:(.*?)(Skills:|$)\", cv_text, re.DOTALL)\n",
    "#     if experience_section:\n",
    "#         experience_lines = experience_section.group(1).strip().split(\"\\n\")\n",
    "#         cv_data[\"experience\"] = [line.strip() for line in experience_lines if line.strip()]\n",
    "\n",
    "#     # Extract skills\n",
    "#     skills_section = re.search(r\"Skills:(.*?)$\", cv_text, re.DOTALL)\n",
    "#     if skills_section:\n",
    "#         skills_lines = skills_section.group(1).strip().split(\"\\n\")\n",
    "#         cv_data[\"skills\"] = [line.strip() for line in skills_lines if line.strip()]\n",
    "\n",
    "#     return cv_data\n",
    "\n",
    "# # Example CV text\n",
    "# cv_text = \"\"\"\n",
    "# Name: John Doe\n",
    "# Email: johndoe@example.com\n",
    "# Phone: +1234567890\n",
    "\n",
    "# Education:\n",
    "# - Bachelor of Science in Computer Science, XYZ University, 2015-2019\n",
    "# - Master of Science in Data Science, ABC University, 2019-2021\n",
    "\n",
    "# Experience:\n",
    "# - Software Engineer at TechCorp, 2021-Present\n",
    "# - Data Analyst at DataWorks, 2019-2021\n",
    "\n",
    "# Skills:\n",
    "# - Python\n",
    "# - Machine Learning\n",
    "# - SQL\n",
    "# - Data Analysis\n",
    "# \"\"\"\n",
    "\n",
    "# # Extract information from the CV\n",
    "# cv_data = extract_cv_info(cv_text)\n",
    "# print(cv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read CV from text file\n",
    "# with open(\"cv1.txt\", \"r\") as file:\n",
    "#     cv_text = file.read()\n",
    "\n",
    "# Read job description from text file\n",
    "with open(\"Job Description1.txt\", \"r\") as file:\n",
    "    job_description = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You are an intelligent assistant designed to extract structured data from a CV. Your task is to analyze the CV provided and extract the following information. If any information is missing, mark it as \"Not Available.\" Provide the results in a clear and concise plain text format.\n",
    "\n",
    "---\n",
    "\n",
    "### Data to Extract:\n",
    "\n",
    "1. **Name**: Extract the full name of the individual.\n",
    "2. **Contact Information**:\n",
    "   - Email address\n",
    "   - Phone number\n",
    "3. **Education History**:\n",
    "   - Degree(s) earned (e.g., Bachelor of Science in Computer Science)\n",
    "   - Institution(s) attended (e.g., University of XYZ)\n",
    "   - Year(s) of graduation, if available\n",
    "4. **Work Experience**:\n",
    "   - Job title(s) (e.g., Software Engineer)\n",
    "   - Company name(s) (e.g., ABC Corp)\n",
    "   - Duration of employment (e.g., Jan 2020 – Dec 2022), if available\n",
    "   - Include all experiences, even if they are brief or incomplete.\n",
    "5. **Skills**:\n",
    "   - List all skills mentioned in the CV, including:\n",
    "     - Technical skills (e.g., Python, TensorFlow, Docker)\n",
    "     - Tools and frameworks (e.g., React, Flask)\n",
    "     - Programming languages (e.g., Java, C++)\n",
    "     - Soft skills (e.g., teamwork, problem-solving)\n",
    "   - Identify skills mentioned in any section of the CV, not just under a \"Skills\" heading.\n",
    "\n",
    "---\n",
    "\n",
    "### Output Format:\n",
    "\n",
    "Return the extracted information in the following plain text format:\n",
    "Name: [Full Name]\n",
    "\n",
    "Contact Information:\n",
    "Email: [Email Address]\n",
    "Phone: [Phone Number]\n",
    "\n",
    "Education History:\n",
    "\n",
    "[Degree], [Institution], [Year of Graduation]\n",
    "\n",
    "[Degree], [Institution], [Year of Graduation]\n",
    "\n",
    "Work Experience:\n",
    "\n",
    "[Job Title], [Company], [Duration]\n",
    "\n",
    "[Job Title], [Company], [Duration]\n",
    "\n",
    "Skills:\n",
    "\n",
    "[Skill 1]\n",
    "\n",
    "[Skill 2]\n",
    "\n",
    "[Skill 3]\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Additional Instructions:\n",
    "\n",
    "1. **Thorough Analysis**:\n",
    "   - Analyze every section of the CV, including headers, bullet points, and paragraphs.\n",
    "   - Extract information even if it is not explicitly labeled (e.g., skills mentioned in job descriptions).\n",
    "\n",
    "2. **Multiple Entries**:\n",
    "   - If the CV contains multiple entries for education or work experience, include all of them in the output.\n",
    "\n",
    "3. **Skills Extraction**:\n",
    "   - Extract all skills mentioned in the CV, including those embedded in job descriptions, project details, or other sections.\n",
    "   - Include both technical and soft skills.\n",
    "\n",
    "4. **Missing Information**:\n",
    "   - If a field is missing (e.g., no graduation year for education), mark it as \"Not Available.\"\n",
    "\n",
    "5. **Be Precise**:\n",
    "   - Ensure the extracted information is accurate and matches the content of the CV.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Example CV Text\n",
    "Name: John Smith\n",
    "\n",
    "Contact Information:\n",
    "Email: john.smith@example.com\n",
    "Phone: +1 555 123 4567\n",
    "\n",
    "Education History:\n",
    "- Master of Science in Computer Science, Stanford University, 2021\n",
    "- Bachelor of Science in Electrical Engineering, MIT, 2019\n",
    "\n",
    "Work Experience:\n",
    "- Senior Software Engineer, Tech Innovators Inc., Jan 2022 – Present\n",
    "- Software Engineer, CodeCraft LLC, Jun 2019 – Dec 2021\n",
    "\n",
    "Skills:\n",
    "- Python\n",
    "- Java\n",
    "- JavaScript\n",
    "- Flask\n",
    "- React\n",
    "- TensorFlow\n",
    "- Docker\n",
    "- AWS\n",
    "- Git\n",
    "- Leadership\n",
    "- Team Collaboration\n",
    "- Problem Solving\n",
    "\n",
    "Expected Output Using the Final Prompt\n",
    "Name: John Smith\n",
    "\n",
    "Contact Information:\n",
    "Email: john.smith@example.com\n",
    "Phone: +1 555 123 4567\n",
    "\n",
    "Education History:\n",
    "- Master of Science in Computer Science, Stanford University, 2021\n",
    "- Bachelor of Science in Electrical Engineering, MIT, 2019\n",
    "\n",
    "Work Experience:\n",
    "- Senior Software Engineer, Tech Innovators Inc., Jan 2022 – Present\n",
    "- Software Engineer, CodeCraft LLC, Jun 2019 – Dec 2021\n",
    "\n",
    "Skills:\n",
    "- Python\n",
    "- Java\n",
    "- JavaScript\n",
    "- Flask\n",
    "- React\n",
    "- TensorFlow\n",
    "- Docker\n",
    "- AWS\n",
    "- Git\n",
    "- Leadership\n",
    "- Team Collaboration\n",
    "- Problem Solving\n",
    "\n",
    "### Task:\n",
    "For the following CV, extract the information, please:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted CV Data: Name: Bassant Elsayed\n",
      "\n",
      "Contact Information:\n",
      "Email: bassantelsayed198@gmail.com\n",
      "Phone Number: +201093131597\n",
      "LinkedIn Profile: <https://www.linkedin.com/in/basant-elsayed-98106b161/>\n",
      "Github Handle: <https://github.com/Baasant>\n",
      "\n",
      "Introduction:\n",
      "I am a machine learning engineer with expertise in AI, deep learning, and NLP, specializing in deploying solutions that drive efficiency and enhance decision-making across industries.\n",
      "\n",
      "Experience:\n",
      "\n",
      "Machine Learning Engineer, Valeo– Egypt (May 2023–present)\n",
      "\n",
      "* Deployed an AI solution with two primary functions:\n",
      "\t1. Automated the generation of daily and monthly issue reports, reducing the manual effort by 60%.\n",
      "\t2. AI-based system for Jira ticket classification and auto-resolution, maintaining high accuracy while reducing resolution time by 30%.\n",
      "* Streamlined analysis of stakeholder requirements by fine-tuning LLM, achieving a 70% reduction in manual effort.\n",
      "\n",
      "Machine Learning Engineer, Omega Wireless– USA (Aug 2022–May 2023)\n",
      "\n",
      "* Improved tumor segmentation accuracy by 85% with U-Net and ResNet using enhanced data augmentation and preprocessing techniques.\n",
      "* Developed a deep RNN model using Python, Keras, and LSTM, leveraging the BOCANet framework to achieve 80% accuracy in enhancing sequential data processing.\n",
      "\n",
      "Research Assistant, University of Nile– Egypt (May 2022–Aug 2022)\n",
      "\n",
      "* Achieved 94% classification accuracy in tumor research using CNNs (VGG16, ResNet50, InceptionV3) on medical images through advanced preprocessing and modeling.\n",
      "\n",
      "University of Cairo, BS in Engineering (Sept 2016–May 2021)\n",
      "\n",
      "* Major: Electronics and Electrical Communication Engineering (EECE)\n",
      "* Coursework: Electronics, signal processing, communications, and systems engineering\n",
      "\n",
      "Technical Skills:\n",
      "\n",
      "Programming & Frameworks: Python, PyTorch, TensorFlow, Hugging Face Transformers\n",
      "\n",
      "NLP & LLM Expertise: Fine-tuning Transformer-based models (LLaMA, GPT, BERT), prompt engineering, text classification, sentiment analysis\n",
      "\n",
      "AI & ML Expertise: Sequence Modeling (LSTM, GRU), Transfer Learning, Few-shot and Zero-shot Learning, Model Deployment (ONNX, TensorRT)\n",
      "\n",
      "Tools & Platforms: LangChain, Docker, MLflow, Jenkins, FastAPI, Django\n",
      "\n",
      "Data Processing: Text Preprocessing, Tokenization, Feature Engineering, Data Augmentation.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "# Load spaCy model for basic NER (if needed)\n",
    "\n",
    "# Initialize the LLM (replace \"deepseek-r1\" with the actual model name if different)\n",
    "llm = Ollama(model=\"llama2\", temperature=0.7)\n",
    "\n",
    "# Function to extract information from CV text using LLM\n",
    "def extract_cv_info_with_llm(cv_text,prompt):\n",
    "    # Define a prompt for the LLM to extract structured information\n",
    "    prompt=prompt+cv_text\n",
    "\n",
    "    # Use the LLM to generate the structured output\n",
    "    response = llm(prompt)\n",
    "    return response\n",
    "    \n",
    "with open(\"cv.txt\", \"r\") as file:\n",
    "    cv_text = file.read()\n",
    "\n",
    "# Extract information from the CV using LLM\n",
    "cv_data = extract_cv_info_with_llm(cv_text,prompt)\n",
    "print(\"Extracted CV Data:\", cv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Recommendation Letter:\n",
      " Dear Hiring Manager,\n",
      "\n",
      "I am writing to express my interest in the Data Scientist position at [Company Name]. As a machine learning engineer with a strong background in AI, deep learning, and NLP, I believe I possess the skills and experience necessary to excel in this role.\n",
      "\n",
      "My experience working as a Machine Learning Engineer at Valeo-Egypt and Omega Wireless-USA has given me hands-on experience in deploying solutions that drive efficiency and enhance decision-making across industries. In my current position, I have successfully deployed an AI solution with two primary functions: automated the generation of daily and monthly issue reports, reducing manual effort by 60%, and developed an AI-based system for Jira ticket classification and auto-resolution, maintaining high accuracy while reducing resolution time by 30%. Additionally, I have streamlined analysis of stakeholder requirements by fine-tuning LLM, achieving a 70% reduction in manual effort.\n",
      "\n",
      "My expertise in programming and frameworks includes Python, PyTorch, TensorFlow, Hugging Face Transformers. My proficiency in NLP and LLM allows me to fine-tune transformer-based models (LLaMA, GPT, BERT), create prompts, perform text classification, sentiment analysis, and more. Furthermore, I have experience with AI and ML techniques such as sequence modeling (LSTM, GRU), transfer learning, few-shot and zero-shot learning, and model deployment (ONNX, TensorRT).\n",
      "\n",
      "In my current role, I have used tools and platforms like LangChain, Docker, MLflow, Jenkins, FastAPI, and Django to manage data processing tasks. My technical skills include text preprocessing, tokenization, feature engineering, and data augmentation.\n",
      "\n",
      "I hold a BS in Engineering from the University of Cairo, majoring in Electronics and Electrical Communication Engineering (EECE). My coursework included electronics, signal processing, communications, and systems engineering.\n",
      "\n",
      "As a Data Scientist at [Company Name], I am committed to using my skills and experience to help the organization achieve its goals through data-driven insights. I am excited about the opportunity to work with your team and contribute to the success of the company. Thank you for considering my application.\n",
      "\n",
      "Sincerely,\n",
      "Bassant Elsayed\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "# Load LLaMA 2 model using Ollama\n",
    "llm = Ollama(model=\"llama2\", temperature=0.7)\n",
    "\n",
    "# Function to generate a recommendation letter\n",
    "def generate_recommendation_letter(cv_data, job_description):\n",
    "    # Prepare the prompt\n",
    "    prompt = f\"\"\"\n",
    "    I need a cover letter based on their CV and the job description provided. The letter should emphasize the candidate's relevant skills, \n",
    "    experience, and achievements while tailoring the content to the requirements of the job. Below are the details:\n",
    "\n",
    "    CV:\n",
    "    {cv_data}\n",
    "    \n",
    "    Job Description:\n",
    "    {job_description}\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate the recommendation letter using LLaMA 2\n",
    "    recommendation_letter = llm(prompt)\n",
    "    return recommendation_letter\n",
    "\n",
    "# Generate the recommendation letter\n",
    "recommendation_letter = generate_recommendation_letter(cv_data, job_description)\n",
    "print(\"Generated Recommendation Letter:\\n\", recommendation_letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"recommendation_letter1.txt\", \"w\") as file:\n",
    "    file.write(recommendation_letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "# Load pre-trained GPT-2 model and tokenizer\n",
    "model_name = \"gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Calculate perplexity\n",
    "def calculate_perplexity(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "        loss = outputs.loss\n",
    "        perplexity = torch.exp(loss)\n",
    "    return perplexity.item()\n",
    "\n",
    "# Example generated text\n",
    "perplexity = calculate_perplexity(recommendation_letter)\n",
    "print(\"Perplexity:\", perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textstat\n",
    "\n",
    "# Calculate Flesch-Kincaid readability score\n",
    "def calculate_readability(text):\n",
    "    return textstat.flesch_reading_ease(text)\n",
    "\n",
    "# Example generated text\n",
    "readability = calculate_readability(recommendation_letter)\n",
    "print(\"Readability Score:\", readability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
